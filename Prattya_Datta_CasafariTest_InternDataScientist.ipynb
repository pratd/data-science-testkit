{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prattya Datta_CasafariTest_InternDataScientist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/pratd/data-science-testkit/blob/master/Prattya_Datta_CasafariTest_InternDataScientist.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "6mEGUK7rYoRC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Casafari Take-Home Challenge\n",
        "\n",
        "### Personal Identification\n",
        "Fill here your personal information to accelerate the assessment by our team:\n",
        "* Your name;\n",
        "* Link to your Git and LinkedIn profile;\n",
        "* Seniority level and years of experience;\n",
        "* Position you applied for and the desired scope of tasks in the 1st year, 2nd year, split by years;\n",
        "* Salary expectations in the 1st year, 2nd year (gross per annum, split by years.)\n",
        "\n",
        "### General Information\n",
        "\n",
        "The test is split in three parts and it was designed to give you a complete, yet short, overview of some our daily activities as data scientist at Casafari. \n",
        "\n",
        "The first two parts (Data Extraction and Data Querying) are straightforward and each one is worth 25% of the overall score. The last part , worth 50% of the overall score, is more open-ended and meant to stretch your data science knowledge. Each section has one extra challenge. They are not mandatory nor counted in the general score, but if you have time, they are the chance to impress us with your extraordinary skills.\n",
        "\n",
        "### Guidelines\n",
        "* We expect that the test should take around 6 hours to do. However, we strongly advise you to carefully read this assignment, think about approaches and try to understand the data before diving into the questions. You are free to spend as much time on it as you want, within the timeframe given by our recruiter.\n",
        "* **You can complete this assignment working on this Google Colab, or if you prefer you can use download it and use it as standalone jupyter notebook and send them back to us together with the relevant files.**\n",
        "* In case of using this Google Colab, you'll need to download those files in [this link](https://drive.google.com/open?id=1GvESbHspNnPhRBGt-FWEG5eOWA1Pdckp) and upload it on this notebook running the cell below.\n",
        "* If you want to use some python packages that are not yet installed on this notebook, use !pip install package."
      ]
    },
    {
      "metadata": {
        "id": "wn82o9okMFJR",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "1e42b2ad-b274-42e4-829c-3d7dff774cf1"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1f2f2bcf-c991-4f0b-b183-700bf719b952\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1f2f2bcf-c991-4f0b-b183-700bf719b952\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sample.json to sample.json\n",
            "Saving properties.csv to properties.csv\n",
            "Saving listing.html to listing.html\n",
            "Saving agents.csv to agents.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LT_oz7zmYwoL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Extraction (CSS + REGEX)\n",
        "\n",
        "Casafari tracks the entire real estate market by aggregating properties from thousands of different websites. The first step of this process is to collect all the relevant information using web crawlers. This task will give a brief overview of how this extraction is made. \n",
        "\n",
        "The task consists of 3 parts, which will evaluate your skills in CSS3 selectors and regular expressions knowledge, which are essential to data extraction processes. We believe that even if you do not have previous knowledge of CSS, HTML and REGEX, you should be able to complete this task in less than a hour. There are many tutorials and informations on how to use CSS3 selectors and regular expressions to extract data. Do not be afraid to google it! This task is also a evaluation of your learning capabilities.\n",
        "\n",
        "The normal questions already have some examples and can be solved only by filling the CSS3 selectors or the regular expressions in the given space. You can check if you have the correct results by running the pre-made script after it. However, if you feel comfortable, you can use another python package and rewrite the script in a similar way to extract the data.\n",
        "\n",
        "For the extra challenges, you'll need to construct the scripts from scratch."
      ]
    },
    {
      "metadata": {
        "id": "D58kOtOXjrR7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__(1)__ For the following task, use the _listing.html_ file, which represents a listings for a property. Open the HTML file on your browser, investigate it with the Inspect tool, view the source code and explore it. \n",
        "After that, fill the CSS3 selectors in the following script to extract the following information about this property:\n",
        "\n",
        "* Number of bathrooms\n",
        "* Number of bedrooms\n",
        "* Living Area\n",
        "* Energy Rating\n",
        "* Description\n",
        "* Agent Name\n",
        "* Extract the location of the property"
      ]
    },
    {
      "metadata": {
        "id": "_ubceG6_rEek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "ff35fa6c-9eb8-495f-d287-2bcdea85da1d"
      },
      "cell_type": "code",
      "source": [
        "!pip install lxml\n",
        "!pip install cssselect"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lxml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/a4/9eea8035fc7c7670e5eab97f34ff2ef0ddd78a491bf96df5accedb0e63f5/lxml-4.2.5-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.8MB 5.4MB/s \n",
            "\u001b[?25hInstalling collected packages: lxml\n",
            "Successfully installed lxml-4.2.5\n",
            "Collecting cssselect\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/44/25b7283e50585f0b4156960691d951b05d061abf4a714078393e51929b30/cssselect-1.0.3-py2.py3-none-any.whl\n",
            "Installing collected packages: cssselect\n",
            "Successfully installed cssselect-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cqba2Ye43Hyy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# EXAMPLE SELECTOR TO EXTRACT THE PROPERTY TYPE\n",
        "Selector_Example = \"h1.lbl_titulo\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-UYR51QwrYWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b75a25a-d67c-40a6-e416-a0079b74f8c8"
      },
      "cell_type": "code",
      "source": [
        "# EXAMPLE CODE, RUN TO CHECK THE EXAMPLE SELECTOR \n",
        "\n",
        "from lxml import html,etree\n",
        "\n",
        "with open(r'listing.html', \"r\") as f:\n",
        "    page = f.read()\n",
        "tree = html.fromstring(page)\n",
        "\n",
        "print('Example -> Property type: {}'.format(tree.cssselect(Selector_Example)[0].text))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example -> Property type: 3 Bedroom House\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M7MJswrmP89Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that you understand the example, just fill the CSS selectors here and check it by running the below cells:"
      ]
    },
    {
      "metadata": {
        "id": "o-2ra_gioTOy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############## Q1 ANSWERS ##################\n",
        "Selector_1 = \"ul.bloco-dados li:nth-child(4) span\"\n",
        "Selector_2 = \"ul.bloco-dados li:nth-child(5) span\"\n",
        "Selector_3 = \"ul.bloco-dados li:nth-child(3) span\"\n",
        "Selector_4 = \"ul.bloco-dados li:nth-child(2) span\"\n",
        "Selector_5 = \"div.bloco-imovel-texto p\"\n",
        "Selector_6 = \"div.lbl_titulo\"\n",
        "Selector_7 = \"div#Cpl_pnl_mapa span#Cpl_lbl_morada.lbl_morada\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AaJuBU1nqsub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "bd29c105-b561-4502-aa30-aa019d2b8abc"
      },
      "cell_type": "code",
      "source": [
        "############### RUN TO CHECK YOUR ANSWERS ##################\n",
        "print('Bathrooms: {}'.format(tree.cssselect(Selector_1)[0].text))\n",
        "print('')\n",
        "print('Bedrooms: {}'.format(tree.cssselect(Selector_2)[0].text))\n",
        "print('')\n",
        "print('Total area: {}'.format(tree.cssselect(Selector_3)[0].text)+\"2\")\n",
        "print('')\n",
        "print('Living area: {}'.format(tree.cssselect(Selector_4)[0].text)+\"2\")\n",
        "print('')\n",
        "print('Description: {}'.format(tree.cssselect(Selector_5)[0].text))\n",
        "print('')\n",
        "print('Agent name: {}'.format(tree.cssselect(Selector_6)[0].text))\n",
        "print('')\n",
        "print('Location: {}'.format(tree.cssselect(Selector_7)[0].text))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bathrooms:  1 \n",
            "\n",
            "Bedrooms:  2 \n",
            "\n",
            "Total area:  0 m2\n",
            "\n",
            "Living area:  80 m2\n",
            "\n",
            "Description: At vero eos et accusamus et iusto odio dignissimos ducimus qui blanditiis praesentium voluptatum deleniti atque corrupti quos dolores et quas molestias excepturi sint occaecati cupiditate non provident, similique sunt in culpa qui officia deserunt mollitia animi, id est laborum et dolorum fugaEt harum quidem rerum facilis est et expedita distinctio.Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus.\n",
            "\n",
            "Agent name: Agent John Doe\n",
            "\n",
            "Location: Portugal, Lisboa, Estrela, Lapa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "__U3ndDeRbt6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Extra Challenge 1__:\n",
        "\n",
        "Write from scratch a script to extract and print:\n",
        "* One link that leads to http://mydomain.com/link-to-image\n",
        "* Extract all the features of the property"
      ]
    },
    {
      "metadata": {
        "id": "iLmuSkUFR-LA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############### WRITE THE SCRIPT TO SOLVE THE EXTRA CHALLENGE HERE ##################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5CX07lJog1Jv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__(2)__ In the second part you will still have to use the html file. However, this time, you should use regular expressions to extract the following data from the webpage:\n",
        "\n",
        "* Urls that are links to listings (i.e.: http://mydomain.com/link-to-listing). Do not use the whole url itself in regular expression. It should select only 3 links.\n",
        "* The agent telephone number\n",
        "* The property price"
      ]
    },
    {
      "metadata": {
        "id": "ANpQ4SvPSvpg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# REGEXP EXAMPLE TO EXTRACT THE AGENT EMAIL\n",
        "Regexp_Example = r\"\\\">(.*?@.*?)<\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6mPc9TCF2jOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cee486fa-eeed-4891-fa64-4bf1abcae922"
      },
      "cell_type": "code",
      "source": [
        "# RUN TO CHECK THE EXAMPLE RESULTS\n",
        "import re\n",
        "\n",
        "with open(r'listing.html', \"r\") as f:\n",
        "    page = f.read()\n",
        "\n",
        "print(\"Email extracted: {}\".format(re.findall(Regexp_Example, page)[0]))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Email extracted: casatest@casa.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6z_yGAIm8uyC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR REGULAR EXPRESSIONS HERE\n",
        "Regexp_1 = r\"http://mydomain.com/link-to-listing\"\n",
        "Regexp_2 = r\"Phone Number:(.*?)<\"\n",
        "Regexp_3 = r\"\\>(.*€)<\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SQRCrfpwhsuK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76b07911-1a0f-4f4d-bd0c-1c9befc086fc"
      },
      "cell_type": "code",
      "source": [
        "re.findall(Regexp_1,page)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['http://mydomain.com/link-to-listing', 'http://mydomain.com/link-to-listing', 'http://mydomain.com/link-to-listing']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "metadata": {
        "id": "nRZMlLL8r0Pc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "0fba7774-31c1-49b7-863f-8161689ce1f9"
      },
      "cell_type": "code",
      "source": [
        "############### RUN TO CHECK YOUR ANSWERS ##################\n",
        "print('Links extrated:')\n",
        "for w in re.findall(Regexp_1, page):\n",
        "  print(w)\n",
        "print('')\n",
        "print(\"Agent Phone Number: {}\".format(re.findall(Regexp_2, page)[0]))\n",
        "print('')\n",
        "print(\"Property price: {}\".format(re.findall(Regexp_3, page)[0]))"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Links extrated:\n",
            "http://mydomain.com/link-to-listing\n",
            "http://mydomain.com/link-to-listing\n",
            "http://mydomain.com/link-to-listing\n",
            "\n",
            "Agent Phone Number:  0800-1111\n",
            "\n",
            "Property price: 1.500.000 €\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o4DbKPVDSk8w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Extra Challenge 2:__\n",
        "* Extract latitude and longitude value from html ()_those values are in the html code, but are not shown on the page__)"
      ]
    },
    {
      "metadata": {
        "id": "o5AylkERSo6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "659567f5-846e-46b9-d8e2-564ed0368369"
      },
      "cell_type": "code",
      "source": [
        "############### WRITE THE SCRIPT TO SOLVE THE EXTRA CHALLENGE HERE ##################\n",
        "regexp_4 = \"data-coorgps=(.*?)>\"\n",
        "print(\"Latitude and Longitude: {}\".format(re.findall(regexp_4, page)[0]))"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Latitude and Longitude: \"36.5194999,-4.7743365\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DxAqykAnY22Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__(3)__ For the last task,  use the *sample.json* file. This file contains JSON that has a list of objects inside. Open the file in a code editor, try to identify some pattern on it and check it's structure first. Each object is under unique ID: \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "{ \n",
        "\n",
        "\"SV350\": { ... // data, describing the object ... }, \n",
        "\n",
        "\"fKDFI3\": { ... // data, describing the object ... },\n",
        "\n",
        "...\n",
        "\n",
        "\"38shF\": { ... // data, describing the object ... } \n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Therefore, you need to write one regular expression to extract the following information:\n",
        "* Every unique ID on this file (for example, the first unique ID should be NC065 and the last should be NN574). \n",
        "\n",
        "Hint: The length of your list should be 211"
      ]
    },
    {
      "metadata": {
        "id": "VPI6oVuXURc7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# WRITE YOUR REGULAR EXPRESSION HERE\n",
        "Regexp_JSON = r\":\\[\\[\\\"Property-No.\\\"\\,(.*?)\\]\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sa6N56T4kBx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "40e1d8a6-fd49-42fa-bc8f-27adac4b9f15"
      },
      "cell_type": "code",
      "source": [
        "with open(r'sample.json', \"r\") as f:\n",
        "    json = f.read()\n",
        "\n",
        "print('----- Expressions extracted -----')\n",
        "print(\"First unique id: {}\".format(re.findall(Regexp_JSON, json)[0]))\n",
        "print(\"Last unique id: {}\".format(re.findall(Regexp_JSON, json)[-1]))\n",
        "print(\"Length of list of unique ids: {}\".format(len(re.findall(Regexp_JSON, json))))"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Expressions extracted -----\n",
            "First unique id: \"NC065\"\n",
            "Last unique id: \"NN574\"\n",
            "Length of list of unique ids: 211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yL20DRtYTuc3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Extra Challenge 3:**\n",
        "* Extract all unique IDs that has the expression _\"land\":\"ESP\"_ inside (for example, the object SV350 has this expression inside it)."
      ]
    },
    {
      "metadata": {
        "id": "3waNjkEUTr_t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "############### WRITE THE SCRIPT TO SOLVE THE EXTRA CHALLENGE HERE ##################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YwNzVMIwadT-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Querying (SQL)\n",
        "\n",
        "You have now collected the data, and cleaned it.  It was published in Casafari database and you have to query the data in order to prepare it for analysis. \n",
        "\n",
        "To solve this problem consider the data set provided in _properties.csv_ and _agents.csv_ to test your queries. As before, please fill in your queries in the cells provided (double click the blank cells to fill them in). \n",
        "\n",
        "In this task we just want to evaluate your knowledge of SQL syntax, so keep it simple. Do not try to overclean the data in this task. You'll get to do this on the next task with Python.\n",
        "\n",
        "###Schemas:\n",
        "- PROPERTIES table: \n",
        "  - **id**(PK, INT) - unique identification number of the property ad listing\n",
        "  - **title**(VARCHAR) - title of the property ad listing\n",
        "  - **features**(VARCHAR) - field with additional characteristics of the property ad listing\n",
        "  - **living_area**(FLOAT) - living area of the property in square meters\n",
        "  - **total_area**(FLOAT)- total area of the property in square meters\n",
        "   - **plot_area**(FLOAT) - plot area of the property in square meters\n",
        "  - **price**(FLOAT) - selling price of the property in euros\n",
        "  - **agent_id**(INT) - selling agent id\n",
        "  - **createdAt**(DATE) - date in which the property was added to the market\n",
        "- AGENTS table: \n",
        "  - **agent_id**(PK, INT) - selling agent id\n",
        "  - **company**(VARCHAR) - company for which the agent works\n",
        "\n",
        "###Details of properties:\n",
        "- **locations** can be: Alenquer, Quinta da Marinha, Golden Mile, Nagüeles;\n",
        "- **types** can be: ‘apartment’, ‘penthouse’, ‘duplex’, ‘house’, ‘villa’, ‘country estate’,\n",
        "‘moradia', ‘quinta', ‘plot’, ‘land’; \n",
        "- the property types can be part of the following **property groups**:\n",
        "  1. group **‘apartments’** includes types ‘apartment’, ‘penthouse’, ‘duplex’;\n",
        "  2. group **‘‘houses’**‘ includes types ‘house’, ‘villa’, ‘country estate’, ‘moradia', ‘quinta’;\n",
        "  3. group **‘‘plots’**‘ includes types ’plot’, ‘land’.\n",
        "- areas:\n",
        " - for the group **‘plots’** use **plot_area**;\n",
        " - for groups **‘apartments’** and **‘houses’** use the highest value between **total_area** or **living_area**;\n",
        "\n",
        "\n",
        "###Questions:\n",
        "- (Q1) Write a query to extract only listings with a property type “quinta” or “house”;\n",
        "- (Q2) Write a query to extract only listings of properties with a pool;\n",
        "- (Q3) Write a query calculating the average price per square meter of all apartments in Nagüeles.\n",
        "- (Q4) Write a query to identify top 3 companies with largest amount of properties\n",
        "- (Q5) Identify top 3 agents by number of properties within each company\n",
        "\n",
        "\n",
        "####HINT:\n",
        "- Check the csv for these 2 parts. Location names and property type can be found within the title. Be aware of possible traps.\n"
      ]
    },
    {
      "metadata": {
        "id": "ZMiufR188DzQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 1:\n",
        "``` **mysql**\n",
        "\n",
        "\n",
        "          SELECT *\n",
        "          FROM \"properties.csv\"\n",
        "          WHERE title LIKE '%quinta%' OR title LIKE '%house%';\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "RB-PnF489SmC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 2:\n",
        "``` **mysql**\n",
        "          SELECT * \n",
        "          FROM \"properties.csv\"\n",
        "          WHERE features LIKE '%pool%';\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "lgzd0mTe9U9O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 3:\n",
        "``` **mysql**\n",
        "          SELECT id,\n",
        "          price/plot_area AS price_per_sqm\n",
        "          FROM \"properties.csv\"\n",
        "          WHERE title LIKE '%Nagueles%'\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "aO_r3o7a9W0t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 4:\n",
        "``` **mysql**\n",
        "          SELECT \"properties.csv\".id, \"properties.csv\".agent_id,\n",
        "          \"agents.csv\".agent_id, \"agents.csv\".company\n",
        "          INTO Table1\n",
        "          FROM \"properties.csv\"\n",
        "          INNER JOIN \"agents.csv\" \n",
        "          ON \"properties.csv\".agent_id = \"agents.csv\".agent_id;\n",
        "          \n",
        "          SELECT COUNT(company)\n",
        "          INTO Tabl1_count\n",
        "          FROM Table1\n",
        "          GROUP BY agent_id\n",
        "          HAVING COUNT(company)>1;\n",
        "          \n",
        "          SELECT TOP 3 * FROM Table_count;\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "Kp0_Ugcs9Y-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 5:\n",
        "``` **mysql**\n",
        "             SELECT COUNT(agent_id), company\n",
        "             INTO Table2_count\n",
        "             FROM Table1\n",
        "             GROUP BY company;\n",
        "             \n",
        "             SELECT TOP 3 agent_id FROM Table2_count\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "_b76pb1YYc5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Extra challenge 4:**\n",
        "- (Q6) Write a query to identify companies with most expensive properties for each month in 2017\n",
        "- (Q7) Write a query to get first and last property posted by each company"
      ]
    },
    {
      "metadata": {
        "id": "LvSED0f19anR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 6:\n",
        "``` **mysql**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "bz3NC48O9cfa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Query 7:\n",
        "``` **mysql**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "D6n6ZF7VahF3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Analysis (Python)\n",
        "\n",
        "\n",
        "You obtained all the data that you need and you now need to run an analysis on the following problem. For this part, feel free to use as many cells as you need below this point. Please use properties.csv as your data source. \n",
        "\n",
        "\n",
        "\n",
        "## Problem \n",
        "A private investor is planning an investment in one of the four locations. In order to decide where to invest he needs to know the price impact of such features as ‘pool’, ‘sea view’ and ‘garage’ on properties in each location.\n",
        "He also asks for the mean price of the properties in each type group (‘apartments’, ‘houses’, ‘plots’) and wants to know about properties in the market that are undervalued and overvalued. In order to accomplish the problem that was described we want you to cover the following steps:\n",
        "\n",
        "####Part 1: Data Cleaning\n",
        "As you have seen previously, a lot of information is present in the title/features fields. From there, we want to extract the relevant information for further analysis, such as:\n",
        " - 1A: Property  **type** (as presented in **Details** above, described in the SQL section) of each property from **title** field\n",
        " - 1B: Property **location** (as presented in **Details** above, described in the SQL section) of each property from ** title** field\n",
        " - 1C: From ** features** field, if a property has:\n",
        "  - a pool\n",
        "  - a garage\n",
        "  - sea view\n",
        "\n",
        "####Expected Outcome for Part 1:\n",
        "- Create a property dataset with the following schema and save it in a csv file:\n",
        "  - id; \n",
        "  - location name\n",
        "  - type\n",
        "  - title\n",
        "  - features\n",
        "  - pool (0/1)\n",
        "  - sea view (0/1)\n",
        "  - garage (0/1)\n",
        "- Pool, sea view and garage should be binary:1 if the property has the feature and 0 if not\n",
        "- For each of the 3 tasks (1A, 1B, 1C), describe in detail the what you did. What are the advantages and disadvantages of your approach?\n",
        "-  Please provide your code in the cells below, in a reproducible and understandable way;"
      ]
    },
    {
      "metadata": {
        "id": "SEbVdIgUv0Qk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import csv\n",
        "import re\n",
        "#read the data\n",
        "f = open('properties.csv','r')\n",
        "csvreader = csv.reader(f)\n",
        "data   = list(csvreader)\n",
        "data.remove(data[0]) # headers removal\n",
        "\n",
        "# putting proper property type values\n",
        "#\n",
        "property_type=[]\n",
        "for item in data:\n",
        "  if re.search(\"apart(|a)ment(|o)\", item[1],re.IGNORECASE) or re.search(\"duplex\", item[1],re.IGNORECASE) or \\\n",
        "  re.search(\"penthouse\", item[1],re.IGNORECASE):\n",
        "    property_type.append('Apartment')  \n",
        "    # the villa is also associated with plot so we have to be careful \n",
        "  elif re.search(\"(?<!plot\\s)villa\", item[1],re.IGNORECASE) or re.search(\"^house$|^Townhouse$|Townhouse\", item[1],re.IGNORECASE)\\\n",
        "  or re.search(\"moradia\", item[1],re.IGNORECASE) or re.search(\"country house\", item[1],re.IGNORECASE) or\\\n",
        "  re.search(\"Quinta\", item[1]):\n",
        "    property_type.append('Houses')\n",
        "  else: \n",
        "    property_type.append('plots')\n",
        "\n",
        "identity=[]\n",
        "location_name=[]\n",
        "title =[]\n",
        "features=[]\n",
        "pool_data=[]\n",
        "sea_view_data=[]\n",
        "garage_data=[]\n",
        "\n",
        "# creation of list for location_names\n",
        "for item in data:\n",
        "  identity.append(item[0])\n",
        "  features.append(item[2])\n",
        "  if re.search(\"Alenquer\",item[1],re.IGNORECASE):\n",
        "    location_name.append('Alenquer')\n",
        "  elif re.search(\"Quinta da Marinha\",item[1],re.IGNORECASE):\n",
        "    location_name.append('Quinta da Marinha')\n",
        "  # for the mixed cases of golden mile and Nargueles we take them into the group of Golden miles\n",
        "  elif re.search('Golden mile',item[1],re.IGNORECASE) or re.search('Marbella Golden mile',item[1],re.IGNORECASE):\n",
        "    location_name.append('Golden Mile')\n",
        "  elif re.search('Nag(ü|u)eles',item[1],re.IGNORECASE):\n",
        "    location_name.append('Nagüeles')\n",
        "# rest of the one hot encoders for features. For that lets extract all the pool/garage/sea_view values\n",
        "for item in data:\n",
        "  if re.search(\"pool\",item[2],re.IGNORECASE) or re.search(\"piscina\",item[1],re.IGNORECASE)\\\n",
        "  or re.search(\"\\s*piscina?\",item[2],re.IGNORECASE) or re.search(\"pool(?<! :No)\", item[1],re.IGNORECASE):\n",
        "    pool_data.append('pool')\n",
        "  elif item[2] == \"\":\n",
        "    pool_data.append('NaN')\n",
        "  else:\n",
        "    pool_data.append('no pool')\n",
        "for item in data:\n",
        "  if re.search(\"garage\",item[2],re.IGNORECASE) or re.search(\"garagem\",item[2],re.IGNORECASE)\\\n",
        "  or re.search(\"\\s*garagem?\",item[2],re.IGNORECASE):\n",
        "    garage_data.append('garage')\n",
        "  elif item[2] == \"\":\n",
        "    garage_data.append('NaN')\n",
        "  else:\n",
        "    garage_data.append('no garage')\n",
        "for item in data:\n",
        "  if re.search(\"sea view\",item[2],re.IGNORECASE) or re.search(\"vista do mar\",item[2],re.IGNORECASE) or\\\n",
        "  re.search(\"sea \",item[2],re.IGNORECASE) or re.search( \"sea\\/\",item[2],re.IGNORECASE):\n",
        "    sea_view_data.append('sea view')\n",
        "  elif item[2] == \"\":\n",
        "    sea_view_data.append('NaN')\n",
        "  else:\n",
        "    sea_view_data.append('no sea view')\n",
        "\n",
        "# putting in the boolean values\n",
        "pool=[]\n",
        "for item in pool_data:\n",
        "  if item == 'pool':\n",
        "    pool.append(1)\n",
        "  elif item == 'no pool':\n",
        "    pool.append(0)\n",
        "  else:\n",
        "    pool.append('NaN')\n",
        "garage= []\n",
        "for item in garage_data:\n",
        "  if item == 'garage':\n",
        "    garage.append(1)\n",
        "  elif item=='no garage':\n",
        "    garage.append(0)\n",
        "  else:\n",
        "    garage.append('NaN')\n",
        "sea_view=[]\n",
        "for item in sea_view_data:\n",
        "  if item == 'sea view':\n",
        "    sea_view.append(1)\n",
        "  elif item == 'no sea view':\n",
        "    sea_view.append(0)\n",
        "  else:\n",
        "    sea_view.append('NaN')\n",
        "#area column\n",
        "plot_area=[]\n",
        "total_area=[]\n",
        "living_area=[]\n",
        "price=[]\n",
        "for item in data:\n",
        "  plot_area.append(item[5])\n",
        "  total_area.append(item[4])\n",
        "  living_area.append(item[3])\n",
        "  price.append(int(item[6]))\n",
        "area=[0]*len(plot_area)\n",
        "for i in range(len(data)):\n",
        "  if property_type[i] == 'plots':\n",
        "    if plot_area[i] == \"\":\n",
        "      area[i]= 0\n",
        "    else:\n",
        "      area[i] = float(plot_area[i])\n",
        "  else:\n",
        "    if living_area[i] == \"\" and total_area[i] == \"\":\n",
        "      area[i] = 0.0\n",
        "    elif living_area[i] == \"\":\n",
        "      area[i]=float(total_area[i])\n",
        "    elif total_area[i] == \"\":\n",
        "      area[i]= float(living_area[i])\n",
        "    else:\n",
        "      area[i]=max(float(living_area[i]),float(total_area[i]))\n",
        "  \n",
        "# extract the non modified columns from csv file\n",
        "\n",
        "for item in data:\n",
        "  title.append(item[1])\n",
        "    \n",
        "#create the dataframe\n",
        "Housing_df = pd.DataFrame()\n",
        "Housing_df['id'] = identity\n",
        "Housing_df['location_name']= location_name\n",
        "Housing_df['type']=property_type\n",
        "Housing_df['title']=title\n",
        "Housing_df['features']=features\n",
        "Housing_df['pool']=pool\n",
        "Housing_df['sea_view']=sea_view\n",
        "Housing_df['garage']=garage\n",
        "Housing_df['area'] = area\n",
        "Housing_df['price']=price\n",
        "Housing_df.to_csv('Housing.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dF17KM1mmy-8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "WS_0w3NAXTZc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Part 2: Identify outliers\n",
        "Now that the data is structured correctly, let's look at which properties are a  good deal for our investor. For this you will need to identify undervalued, overvalued, and normal properties in the dataset. Please use any model you find appropiate in order to obtain this.\n",
        "####Expected Outcome for Part 2:\n",
        "- As before, deliver a csv file with the following format:\n",
        "  - id\n",
        "  - location name\n",
        "  - type\n",
        "  - area\n",
        "  - price\n",
        "  - over-valued (0/1)\n",
        "  - under-valued (0/1)\n",
        "  - normal (0/1)\n",
        "- the new columns should be binary, where for example **over-valued** column would get value 1 if the property is indeed over-valued, 0 otherwise;\n",
        "- A short report (could be a pdf file or new cells within the notebook) containing:\n",
        "  - visualizations (such as scatter plots) discriminating between the undervalued, overvalued and normal properties;\n",
        "  - a explanation of what is the difference between under-valued/over-valued properties and pure data outliers;\n",
        "  - any notes/conclusions you wish to add;\n",
        "- Provide your code in a reproducible way in the cells below;"
      ]
    },
    {
      "metadata": {
        "id": "mhw6aAtC-gSc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since the investor is looking for only a few particular features like sea-view, garage and pool we have to assign weights to each of them. Here the catagory referes to ethe location'.Lets analyze the mean weights in each category feature. We will remove entries where there is no price given"
      ]
    },
    {
      "metadata": {
        "id": "1QZrOT9B-f6i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "Housing_df1=Housing_df[Housing_df.price != 0]\n",
        "Housing_df2=Housing_df1.reset_index()\n",
        "# we also remove data where we have no information about pool or garage or sea view. \n",
        "for i in range(len(Housing_df2.price)):\n",
        "  if Housing_df2.pool[i] =='NaN' or Housing_df2.sea_view[i] == 'NaN' or Housing_df2.garage[i]=='NaN':\n",
        "    Housing_df2.drop(i,inplace=True)\n",
        "# resetting_index\n",
        "Housing_df3 = Housing_df2.reset_index(drop=True)\n",
        "#calculating mean and std deviation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PMUHOfbxEt92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "31cb2a74-bcbd-4893-c0f8-ccfc327a3ecc"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# using a simple polynomial regression to fit the model based on area and selected features\n",
        "# area is an important factor for price decision.\n",
        "# normalize the data based on different groups\n",
        "\n",
        "temp_df= Housing_df3.groupby(['location_name'])[['price','area']].apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
        "temp_df['pool']= Housing_df3['pool']\n",
        "temp_df['sea_view']=Housing_df3['sea_view']\n",
        "temp_df['garage']=Housing_df3['garage']\n",
        "temp_df['type']= Housing_df3['type']\n",
        "temp_df['location_name']= Housing_df3['location_name']\n",
        "temp_df.head()\n"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>area</th>\n",
              "      <th>pool</th>\n",
              "      <th>sea_view</th>\n",
              "      <th>garage</th>\n",
              "      <th>type</th>\n",
              "      <th>location_name</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.957441</td>\n",
              "      <td>0.245139</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Houses</td>\n",
              "      <td>Golden Mile</td>\n",
              "      <td>130728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.060233</td>\n",
              "      <td>0.334258</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>plots</td>\n",
              "      <td>Nagüeles</td>\n",
              "      <td>130856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.074044</td>\n",
              "      <td>0.008518</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Apartment</td>\n",
              "      <td>Golden Mile</td>\n",
              "      <td>130857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.050403</td>\n",
              "      <td>0.004189</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Houses</td>\n",
              "      <td>Golden Mile</td>\n",
              "      <td>130897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.044178</td>\n",
              "      <td>0.025562</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Houses</td>\n",
              "      <td>Golden Mile</td>\n",
              "      <td>130917</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      price      area pool sea_view garage       type location_name      id\n",
              "0  0.957441  0.245139    0        1      0     Houses   Golden Mile  130728\n",
              "1  0.060233  0.334258    0        0      0      plots      Nagüeles  130856\n",
              "2  0.074044  0.008518    1        1      0  Apartment   Golden Mile  130857\n",
              "3  0.050403  0.004189    1        0      0     Houses   Golden Mile  130897\n",
              "4  0.044178  0.025562    1        1      0     Houses   Golden Mile  130917"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "metadata": {
        "id": "AmQZRQDE5Cg_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#extracting arrays from the datframe \n",
        "T1 = temp_df.loc[temp_df['location_name'] == 'Golden Mile']\n",
        "temp1 = T1\n",
        "T2 = T1.reset_index(drop=True)\n",
        "T3 = T2.drop(['type'], axis=1)\n",
        "T4 = T3.drop(['location_name'],axis=1)\n",
        "Array_1 = T4.values\n",
        "X1 = Array_1[:,1:]\n",
        "Y1= Array_1[:,0]\n",
        "T1 = temp_df.loc[temp_df['location_name'] == 'Quinta da Marinha']\n",
        "temp2 = T1\n",
        "T2 = T1.reset_index(drop=True)\n",
        "T3 = T2.drop(['type'], axis=1)\n",
        "T4 = T3.drop(['location_name'],axis=1)\n",
        "Array_1 = T4.values\n",
        "X2 = Array_1[:,1:]\n",
        "Y2= Array_1[:,0]\n",
        "T1 = temp_df.loc[temp_df['location_name'] == 'Nagüeles']\n",
        "temp3 = T1\n",
        "T2 = T1.reset_index(drop=True)\n",
        "T3 = T2.drop(['type'], axis=1)\n",
        "T4 = T3.drop(['location_name'],axis=1)\n",
        "Array_1 = T4.values\n",
        "X3 = Array_1[:,1:]\n",
        "Y3= Array_1[:,0]\n",
        "T1 = temp_df.loc[temp_df['location_name'] == 'Alenquer']\n",
        "temp4 = T1\n",
        "T2 = T1.reset_index(drop=True)\n",
        "T3 = T2.drop(['type'], axis=1)\n",
        "T4 = T3.drop(['location_name'],axis=1)\n",
        "Array_1 = T4.values\n",
        "X4 = Array_1[:,1:]\n",
        "Y4= Array_1[:,0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5o8kAUpHjmp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Import function to automatically create polynomial features! \n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "# Import Linear Regression \n",
        "from sklearn.linear_model import LinearRegression\n",
        "# Finally, import function to make a machine learning pipeline\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import cross_validation\n",
        "\n",
        "# concatenating the arrays to get final boolean+ normalized area array for the three\n",
        "# groups of houses\n",
        "Xtemp = PolynomialFeatures(interaction_only=True).fit_transform(X1[:,1:]).astype(int)\n",
        "x1 = np.column_stack((Xtemp,X1[:,0]))\n",
        "Xtemp = PolynomialFeatures(interaction_only=True).fit_transform(X2[:,1:]).astype(int)\n",
        "x2 = np.column_stack((Xtemp,X2[:,0]))\n",
        "Xtemp = PolynomialFeatures(interaction_only=True).fit_transform(X3[:,1:]).astype(int)\n",
        "x3 = np.column_stack((Xtemp,X3[:,0]))\n",
        "Xtemp = PolynomialFeatures(interaction_only=True).fit_transform(X4[:,1:]).astype(int)\n",
        "x4 = np.column_stack((Xtemp,X4[:,0]))\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b-bqMYBB_xeV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Min and max degree of polynomials features to consider\n",
        "degree_min = 1\n",
        "degree_max = 2\n",
        "degrees=np.arange(degree_min,degree_max,1)\n",
        "for i in range(len(degrees)):\n",
        "    \n",
        "    poly = PolynomialFeatures(degree=degrees[i],\n",
        "                                             include_bias=False)\n",
        "    linear_regression = LinearRegression()\n",
        "    pipeline = Pipeline([(\"polynomial_features\", poly),\n",
        "                         (\"linear_regression\", linear_regression)])\n",
        "    #shuffling the data\n",
        "    xtemp =np.take(x4,np.random.permutation(x4.shape[0]),axis=0,out=x4)\n",
        "    X = poly.fit_transform(xtemp)\n",
        "    pipeline.fit(X, Y4)\n",
        "\n",
        "    # Evaluate the models using crossvalidation\n",
        "    scores = cross_validation.cross_val_score(pipeline,\n",
        "        X, Y4, scoring=\"mean_squared_error\", cv=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5DYPHZ9GQd_1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_predict1= pipeline.predict(xtemp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "81QdzQ3zzbvw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_predict2=pipeline.predict(xtemp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sI5LgP69zfe1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_predict3=pipeline.predict(xtemp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VkppXLZeAKwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_predict4=pipeline.predict(xtemp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gk-_Zbsqz_o7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next we find the interquartile range using the best fit predicted values and we assign overvalued or undervalued properties based on them"
      ]
    },
    {
      "metadata": {
        "id": "NCl20tOs2Xif",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we define IQR or interquartile range to detect outliers for each group\n",
        "from numpy import percentile\n",
        "# calculate interquartile range and the outliers based on the cutoff\n",
        "q25, q75 = percentile(y_predict1, 25), percentile(y_predict1, 75)\n",
        "iqr = q75 - q25\n",
        "cut_off = iqr * 1.5\n",
        "lower1, upper1 = q25 - cut_off, q75 + cut_off\n",
        "\n",
        "q25, q75 = percentile(y_predict2, 25), percentile(y_predict2, 75)\n",
        "iqr = q75 - q25\n",
        "cut_off = iqr * 1.5\n",
        "lower2, upper2 = q25 - cut_off, q75 + cut_off\n",
        "\n",
        "q25, q75 = percentile(y_predict3, 25), percentile(y_predict3, 75)\n",
        "iqr = q75 - q25\n",
        "cut_off = iqr * 1.5\n",
        "lower3, upper3 = q25 - cut_off, q75 + cut_off\n",
        "\n",
        "q25, q75 = percentile(y_predict4, 25), percentile(y_predict4, 75)\n",
        "iqr = q75 - q25\n",
        "cut_off = iqr * 1.5\n",
        "lower4, upper4 = q25 - cut_off, q75 + cut_off"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ECxIBoOiFMZT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#find the overvalued and undervalued properties and output the results\n",
        "overvalue1 = [x for x in y_predict1 if  x > upper1]\n",
        "undervalue1 = [x for x in y_predict1 if  x < lower1]\n",
        "overvalue2 = [x for x in y_predict2 if  x > upper2]\n",
        "undervalue2 = [x for x in y_predict2 if  x < lower2]\n",
        "overvalue3 = [x for x in y_predict3 if  x > upper3]\n",
        "undervalue3 = [x for x in y_predict3 if  x < lower3]\n",
        "overvalue4 = [x for x in y_predict4 if  x > upper4]\n",
        "undervalue4 = [x for x in y_predict4 if  x < lower4]\n",
        "#append all the values\n",
        "\n",
        "overvalued=[]\n",
        "undervalued=[]\n",
        "normalvalued=[]\n",
        "t1=[]\n",
        "\n",
        "for item in y_predict1:\n",
        "  flag=0\n",
        "  for item1 in overvalue1:\n",
        "    if item1 == item:\n",
        "      flag=0\n",
        "      break\n",
        "    else:\n",
        "      flag+=1\n",
        "  if flag > 0:\n",
        "    overvalued.append(0)\n",
        "  else:\n",
        "    overvalued.append(1)\n",
        "     \n",
        "for item in y_predict1:\n",
        "  flag=0\n",
        "  for item1 in undervalue1:\n",
        "    if item1 == item:\n",
        "      flag=0\n",
        "      break\n",
        "    else:\n",
        "      flag+=1\n",
        "  if flag > 0:\n",
        "    undervalued.append(0)\n",
        "  else:\n",
        "    undervalued.append(1)\n",
        "            \n",
        "# repeating again for the next groups     \n",
        "      \n",
        "for item in y_predict2:\n",
        "  flag=0\n",
        "  for item1 in overvalue2:\n",
        "    if item1 == item:\n",
        "      flag=0\n",
        "      break\n",
        "    else:\n",
        "      flag+=1\n",
        "  if flag > 0:\n",
        "    overvalued.append(0)\n",
        "  else:\n",
        "    overvalued.append(1)\n",
        "      \n",
        "for item in y_predict2:\n",
        "  flag=0\n",
        "  for item1 in undervalue2:\n",
        "    if item1 == item:\n",
        "      flag=0\n",
        "      break\n",
        "    else:\n",
        "      flag+=1\n",
        "  if flag > 0:\n",
        "    undervalued.append(0)\n",
        "  else:\n",
        "    undervalued.append(1)  \n",
        "\n",
        "for item in y_predict3:\n",
        "  flag=0\n",
        "  for item1 in overvalue3:\n",
        "    if item1 == item:\n",
        "      flag=0\n",
        "      break\n",
        "    else:\n",
        "      flag+=1\n",
        "  if flag > 0:\n",
        "    overvalued.append(0)\n",
        "  else:\n",
        "    overvalued.append(1)\n",
        "      \n",
        "for item in y_predict3:\n",
        "  flag=0\n",
        "  for item1 in undervalue3:\n",
        "    if item1 == item:\n",
        "      flag=0\n",
        "      break\n",
        "    else:\n",
        "      flag+=1\n",
        "  if flag > 0:\n",
        "    undervalued.append(0)\n",
        "  else:\n",
        "    undervalued.append(1)\n",
        "\n",
        "for item in y_predict4:\n",
        "  flag=0\n",
        "  for item1 in overvalue4:\n",
        "    if item1 == item:\n",
        "      flag=0\n",
        "      break\n",
        "    else:\n",
        "      flag+=1\n",
        "  if flag > 0:\n",
        "    overvalued.append(0)\n",
        "  else:\n",
        "    overvalued.append(1)\n",
        "      \n",
        "for item in y_predict4:\n",
        "  flag=0\n",
        "  for item1 in undervalue4:\n",
        "    if item1 == item:\n",
        "      flag=0\n",
        "      break\n",
        "    else:\n",
        "      flag+=1\n",
        "  if flag > 0:\n",
        "    undervalued.append(0)\n",
        "  else:\n",
        "    undervalued.append(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0YsJElgIhM_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Final_df=pd.DataFrame()\n",
        "Final_df=Final_df.append(temp1, ignore_index=True)\n",
        "Final_df=Final_df.append(temp2, ignore_index=True)\n",
        "Final_df=Final_df.append(temp3, ignore_index=True)\n",
        "Final_df=Final_df.append(temp4, ignore_index=True)\n",
        "Final_df['overvalued']=overvalued\n",
        "Final_df['undervalued']=undervalued\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eL86A50mq_Ws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "normalvalued=[]\n",
        "for item in (Final_df['overvalued']-Final_df['undervalued']):\n",
        "  if item == 0:\n",
        "    normalvalued.append(1)\n",
        "  else:\n",
        "    normalvalued.append(0)\n",
        "Final_df['Normal valued']=normalvalued\n",
        "Final_df['id']=Housing_df3['id']\n",
        "Final_df['Total price']=Housing_df3['price']\n",
        "Final_df['Total area'] =Housing_df3['area']\n",
        "Final_df['title']=Housing_df3['title']\n",
        "Final_df['features']=Housing_df3['features']\n",
        "Final_df.drop(['area'],axis=1,inplace=True)\n",
        "Final_df.drop(['price'],axis=1,inplace=True)\n",
        "# the following gives the csv file of overvalued and undervalued properties\n",
        "Final_df.to_csv('Housing_valuation.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_m0oYlVUXWqI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Part 3: Theoretical questions\n",
        "- Mention at least 2 hidden traps you found while solving the problems and what would help you to clean the data set;\n",
        "- Describe in detail how you would evaluate the price impact of features such as sea view, pool and garage considering the dataset provided. Your answer should also include how would you deal with missing values, outliers and duplicated listings (same property listing published by different agencies);\n"
      ]
    },
    {
      "metadata": {
        "id": "l7s0EzCEqlLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The two hidden traps are:.=\n",
        "1. Features and titles had multiple features which were linked for eg., Nagueles and Golden Mile. \n",
        "2. Many features had missing value and there were some spelling differences.\n",
        "3. Also, I didnot shuffle the data  which could skew the emodel\n"
      ]
    },
    {
      "metadata": {
        "id": "WEJZaN7uXaJ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Extra challenge 5:\n",
        "- Describe how would you model the data over time (using createdAt field). What changes over time would you look for and what would you expect the outcomes to be? (i.e. in terms of pricing per location/type)"
      ]
    },
    {
      "metadata": {
        "id": "H63ckTpFr-5_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}